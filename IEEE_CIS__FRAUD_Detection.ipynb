{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IEEE_CIS _FRAUD_Detection",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahullnitp/IEEE-CIS-Fraud-Detection/blob/master/IEEE_CIS__FRAUD_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6URrxADWV2_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Date-28/08/2019\n",
        "\n",
        "In this project i will use classification method on the given dataset and find out which of these instances are seem to be fraud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILwEPJU-FwcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'rahul1704031'\n",
        "os.environ['KAGGLE_KEY'] = 'xxxxxxxxxxxxx'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mEAmotGGTT8",
        "colab_type": "code",
        "outputId": "1d10b3c1-079a-4d0c-ff31-7c9fae84d8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_transaction.csv.zip to /content\n",
            "\r  0% 0.00/52.5M [00:00<?, ?B/s]\r 10% 5.00M/52.5M [00:00<00:00, 52.3MB/s]\r 42% 22.0M/52.5M [00:00<00:00, 66.2MB/s]\r 88% 46.0M/52.5M [00:00<00:00, 84.8MB/s]\n",
            "100% 52.5M/52.5M [00:00<00:00, 151MB/s] \n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.02M [00:00<?, ?B/s]\n",
            "100% 3.02M/3.02M [00:00<00:00, 100MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 53% 25.0M/47.3M [00:00<00:00, 56.9MB/s]\n",
            "100% 47.3M/47.3M [00:00<00:00, 120MB/s] \n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/2.97M [00:00<?, ?B/s]\n",
            "100% 2.97M/2.97M [00:00<00:00, 202MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 165MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLsg7lKzmFIS",
        "colab_type": "code",
        "outputId": "938c4129-be88-4046-c60f-3d6bbea7e4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "!pip3 install catboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/e9/41060f73ca5dcf604f75bc871ee5ce8dcb201897640b37c95aa8b1e139c8/catboost-0.16.5-cp36-none-manylinux1_x86_64.whl (61.9MB)\n",
            "\u001b[K     |████████████████████████████████| 61.9MB 70.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.0.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (2.21.0)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (4.4.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (2018.9)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (2019.6.16)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (4.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.2.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.16.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jBLmt2Tl6eO",
        "colab_type": "code",
        "outputId": "93d016c1-ff1d-455e-a816-6ed9b23113e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import gc\n",
        "from numba import jit    #numba is an open source JIT compiler that translates a subset of python and numpy into fast macine code like LLVM.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "import altair as alt\n",
        "from altair.vega import v5  #Altair is a declarative statistical visualization library in Python, based on Vega-lite .\n",
        "from IPython.display import HTML\n",
        "\n",
        "# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\n",
        "def prepare_altair():\n",
        "    \"\"\"\n",
        "    Helper function to prepare altair for working.\n",
        "    \"\"\"\n",
        "\n",
        "    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n",
        "    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
        "    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
        "    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
        "    noext = \"?noext\"\n",
        "    \n",
        "    paths = {\n",
        "        'vega': vega_url + noext,\n",
        "        'vega-lib': vega_lib_url + noext,\n",
        "        'vega-lite': vega_lite_url + noext,\n",
        "        'vega-embed': vega_embed_url + noext\n",
        "    }\n",
        "    \n",
        "    workaround = f\"\"\"    requirejs.config({{\n",
        "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
        "        paths: {paths}\n",
        "    }});\n",
        "    \"\"\"\n",
        "    \n",
        "    return workaround\n",
        "    \n",
        "\n",
        "def add_autoincrement(render_func):\n",
        "    # Keep track of unique <div/> IDs\n",
        "    cache = {}\n",
        "    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
        "        if autoincrement:\n",
        "            if id in cache:\n",
        "                counter = 1 + cache[id]\n",
        "                cache[id] = counter\n",
        "            else:\n",
        "                cache[id] = 0\n",
        "            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
        "        else:\n",
        "            if id not in cache:\n",
        "                cache[id] = 0\n",
        "            actual_id = id\n",
        "        return render_func(chart, id=actual_id)\n",
        "    # Cache will stay outside and \n",
        "    return wrapped\n",
        "           \n",
        "\n",
        "@add_autoincrement\n",
        "def render(chart, id=\"vega-chart\"):\n",
        "    \"\"\"\n",
        "    Helper function to plot altair visualizations.\n",
        "    \"\"\"\n",
        "    chart_str = \"\"\"\n",
        "    <div id=\"{id}\"></div><script>\n",
        "    require([\"vega-embed\"], function(vg_embed) {{\n",
        "        const spec = {chart};     \n",
        "        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
        "        console.log(\"anything?\");\n",
        "    }});\n",
        "    console.log(\"really...anything?\");\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    return HTML(\n",
        "        chart_str.format(\n",
        "            id=id,\n",
        "            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
        "        )\n",
        "    )\n",
        "    \n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "    \n",
        "\n",
        "@jit\n",
        "def fast_auc(y_true, y_prob):\n",
        "    \"\"\"\n",
        "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    nfalse = 0\n",
        "    auc = 0\n",
        "    n = len(y_true)\n",
        "    for i in range(n):\n",
        "        y_i = y_true[i]\n",
        "        nfalse += (1 - y_i)\n",
        "        auc += y_i * nfalse\n",
        "    auc /= (nfalse * (n - nfalse))\n",
        "    return auc\n",
        "\n",
        "\n",
        "def eval_auc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Fast auc eval function for lgb.\n",
        "    \"\"\"\n",
        "    return 'auc', fast_auc(y_true, y_pred), True\n",
        "\n",
        "\n",
        "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
        "    \"\"\"\n",
        "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
        "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
        "    \"\"\"\n",
        "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
        "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
        "    \n",
        "\n",
        "def train_model_regression(X, X_test, y, params, folds=None, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
        "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3):\n",
        "    \"\"\"\n",
        "    A function to train a variety of regression models.\n",
        "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
        "    \n",
        "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
        "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
        "    :params: y - target\n",
        "    :params: folds - folds to split data\n",
        "    :params: model_type - type of model to use\n",
        "    :params: eval_metric - metric to use\n",
        "    :params: columns - columns to use. If None - use all columns\n",
        "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
        "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
        "    \n",
        "    \"\"\"\n",
        "    columns = X.columns if columns is None else columns\n",
        "    X_test = X_test[columns]\n",
        "    splits = folds.split(X) if splits is None else splits\n",
        "    n_splits = folds.n_splits if splits is None else n_folds\n",
        "    \n",
        "    # to set up scoring parameters\n",
        "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
        "                        'catboost_metric_name': 'MAE',\n",
        "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
        "                    'group_mae': {'lgb_metric_name': 'mae',\n",
        "                        'catboost_metric_name': 'MAE',\n",
        "                        'scoring_function': group_mean_log_mae},\n",
        "                    'mse': {'lgb_metric_name': 'mse',\n",
        "                        'catboost_metric_name': 'MSE',\n",
        "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
        "                    }\n",
        "\n",
        "    \n",
        "    result_dict = {}\n",
        "    \n",
        "    # out-of-fold predictions on train data\n",
        "    oof = np.zeros(len(X))\n",
        "    \n",
        "    # averaged predictions on train data\n",
        "    prediction = np.zeros(len(X_test))\n",
        "    \n",
        "    # list of scores on folds\n",
        "    scores = []\n",
        "    feature_importance = pd.DataFrame()\n",
        "    \n",
        "    # split and train on folds\n",
        "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
        "        if verbose:\n",
        "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
        "        if type(X) == np.ndarray:\n",
        "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
        "            y_train, y_valid = y[train_index], y[valid_index]\n",
        "        else:\n",
        "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
        "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "            \n",
        "        if model_type == 'lgb':\n",
        "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
        "            model.fit(X_train, y_train, \n",
        "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
        "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
        "            \n",
        "            y_pred_valid = model.predict(X_valid)\n",
        "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
        "            \n",
        "        if model_type == 'xgb':\n",
        "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
        "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
        "\n",
        "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
        "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
        "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
        "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
        "        \n",
        "        if model_type == 'sklearn':\n",
        "            model = model\n",
        "            model.fit(X_train, y_train)\n",
        "            \n",
        "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
        "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
        "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
        "            print('')\n",
        "            \n",
        "            y_pred = model.predict(X_test).reshape(-1,)\n",
        "        \n",
        "        if model_type == 'cat':\n",
        "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
        "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
        "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
        "\n",
        "            y_pred_valid = model.predict(X_valid)\n",
        "            y_pred = model.predict(X_test)\n",
        "        \n",
        "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
        "        if eval_metric != 'group_mae':\n",
        "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
        "        else:\n",
        "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
        "\n",
        "        prediction += y_pred    \n",
        "        \n",
        "        if model_type == 'lgb' and plot_feature_importance:\n",
        "            # feature importance\n",
        "            fold_importance = pd.DataFrame()\n",
        "            fold_importance[\"feature\"] = columns\n",
        "            fold_importance[\"importance\"] = model.feature_importances_\n",
        "            fold_importance[\"fold\"] = fold_n + 1\n",
        "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
        "\n",
        "    prediction /= n_splits\n",
        "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
        "    \n",
        "    result_dict['oof'] = oof\n",
        "    result_dict['prediction'] = prediction\n",
        "    result_dict['scores'] = scores\n",
        "    \n",
        "    if model_type == 'lgb':\n",
        "        if plot_feature_importance:\n",
        "            feature_importance[\"importance\"] /= n_splits\n",
        "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
        "                by=\"importance\", ascending=False)[:50].index\n",
        "\n",
        "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
        "\n",
        "            plt.figure(figsize=(16, 12));\n",
        "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
        "            plt.title('LGB Features (avg over folds)');\n",
        "            \n",
        "            result_dict['feature_importance'] = feature_importance\n",
        "        \n",
        "    return result_dict\n",
        "    \n",
        "\n",
        "\n",
        "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n",
        "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3, averaging='usual', n_jobs=-1):\n",
        "    \"\"\"\n",
        "    A function to train a variety of classification models.\n",
        "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
        "    \n",
        "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
        "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
        "    :params: y - target\n",
        "    :params: folds - folds to split data\n",
        "    :params: model_type - type of model to use\n",
        "    :params: eval_metric - metric to use\n",
        "    :params: columns - columns to use. If None - use all columns\n",
        "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
        "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
        "    \n",
        "    \"\"\"\n",
        "    columns = X.columns if columns is None else columns\n",
        "    n_splits = folds.n_splits if splits is None else n_folds\n",
        "    X_test = X_test[columns]\n",
        "    \n",
        "    # to set up scoring parameters\n",
        "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
        "                        'catboost_metric_name': 'AUC',\n",
        "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
        "                    }\n",
        "    \n",
        "    result_dict = {}\n",
        "    if averaging == 'usual':\n",
        "        # out-of-fold predictions on train data\n",
        "        oof = np.zeros((len(X), 1))\n",
        "\n",
        "        # averaged predictions on train data\n",
        "        prediction = np.zeros((len(X_test), 1))\n",
        "        \n",
        "    elif averaging == 'rank':\n",
        "        # out-of-fold predictions on train data\n",
        "        oof = np.zeros((len(X), 1))\n",
        "\n",
        "        # averaged predictions on train data\n",
        "        prediction = np.zeros((len(X_test), 1))\n",
        "\n",
        "    \n",
        "    # list of scores on folds\n",
        "    scores = []\n",
        "    feature_importance = pd.DataFrame()\n",
        "    \n",
        "    # split and train on folds\n",
        "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
        "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
        "        if type(X) == np.ndarray:\n",
        "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
        "            y_train, y_valid = y[train_index], y[valid_index]\n",
        "        else:\n",
        "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
        "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "            \n",
        "        if model_type == 'lgb':\n",
        "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n",
        "            model.fit(X_train, y_train, \n",
        "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
        "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
        "            \n",
        "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
        "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
        "            \n",
        "        if model_type == 'xgb':\n",
        "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
        "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
        "\n",
        "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
        "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
        "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
        "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
        "        \n",
        "        if model_type == 'sklearn':\n",
        "            model = model\n",
        "            model.fit(X_train, y_train)\n",
        "            \n",
        "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
        "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
        "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
        "            print('')\n",
        "            \n",
        "            y_pred = model.predict_proba(X_test)\n",
        "        \n",
        "        if model_type == 'cat':\n",
        "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
        "                                      loss_function=Logloss)\n",
        "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
        "\n",
        "            y_pred_valid = model.predict(X_valid)\n",
        "            y_pred = model.predict(X_test)\n",
        "        \n",
        "        if averaging == 'usual':\n",
        "            \n",
        "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
        "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
        "            \n",
        "            prediction += y_pred.reshape(-1, 1)\n",
        "\n",
        "        elif averaging == 'rank':\n",
        "                                  \n",
        "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
        "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
        "                                  \n",
        "            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n",
        "        \n",
        "        if model_type == 'lgb' and plot_feature_importance:\n",
        "            # feature importance\n",
        "            fold_importance = pd.DataFrame()\n",
        "            fold_importance[\"feature\"] = columns\n",
        "            fold_importance[\"importance\"] = model.feature_importances_\n",
        "            fold_importance[\"fold\"] = fold_n + 1\n",
        "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
        "\n",
        "    prediction /= n_splits\n",
        "    \n",
        "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
        "    \n",
        "    result_dict['oof'] = oof\n",
        "    result_dict['prediction'] = prediction\n",
        "    result_dict['scores'] = scores\n",
        "    \n",
        "    if model_type == 'lgb':\n",
        "        if plot_feature_importance:\n",
        "            feature_importance[\"importance\"] /= n_splits\n",
        "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
        "                by=\"importance\", ascending=False)[:50].index\n",
        "\n",
        "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
        "\n",
        "            plt.figure(figsize=(16, 12));\n",
        "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
        "            plt.title('LGB Features (avg over folds)');\n",
        "            \n",
        "            result_dict['feature_importance'] = feature_importance\n",
        "            result_dict['top_columns'] = cols\n",
        "        \n",
        "    return result_dict\n",
        "\n",
        "# setting up altair\n",
        "workaround = prepare_altair()\n",
        "HTML(\"\".join((\n",
        "    \"<script>\",\n",
        "    workaround,\n",
        "    \"</script>\",\n",
        ")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<script>    requirejs.config({\n",
              "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
              "        paths: {'vega': 'https://cdn.jsdelivr.net/npm/vega@v5.4.0?noext', 'vega-lib': 'https://cdn.jsdelivr.net/npm/vega-lib?noext', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@v3.4.0?noext', 'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@3?noext'}\n",
              "    });\n",
              "    </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjR0ICMQRn0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "import gc\n",
        "from itertools import cycle, islice\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSe6V9adOpWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transact = pd.read_csv('train_transaction.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "test_transact=pd.read_csv('test_transaction.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "train_id=pd.read_csv('train_identity.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "test_id=pd.read_csv('test_identity.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "sample_submission=pd.read_csv('sample_submission.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtWbrvhjFpcU",
        "colab_type": "code",
        "outputId": "e18c32f9-a7c3-4c25-cb2e-c5dc5c0b3d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_transact.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoGSdepMPGCS",
        "colab_type": "code",
        "outputId": "fa180ecc-7c3c-402c-8e00-04418a071251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "train_transact.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZraqrhozChk",
        "colab_type": "code",
        "outputId": "ab723fc1-148c-4952-c5af-2d93ad965043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "train_id.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70787.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-480.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>Android 7.0</td>\n",
              "      <td>samsung browser 6.2</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2220x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987008</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>98945.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>621.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>iOS 11.1.2</td>\n",
              "      <td>mobile safari 11.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1334x750</td>\n",
              "      <td>match_status:1</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>iOS Device</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987010</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>191631.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>121.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>410.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Windows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987011</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>221832.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>176.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7460.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Mac OS X 10_11_6</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x800</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>MacOS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01  ...  DeviceType                     DeviceInfo\n",
              "0        2987004    0.0  ...      mobile  SAMSUNG SM-G892A Build/NRD90M\n",
              "1        2987008   -5.0  ...      mobile                     iOS Device\n",
              "2        2987010   -5.0  ...     desktop                        Windows\n",
              "3        2987011   -5.0  ...     desktop                            NaN\n",
              "4        2987016    0.0  ...     desktop                          MacOS\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zylh8x7Tkj3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=train_transact.merge(train_id,on='TransactionID',how='left')\n",
        "test=test_transact.merge(test_id,on='TransactionID',how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KaHL1umlvXl",
        "colab_type": "code",
        "outputId": "743edf70-1d8c-4a99-e81c-b9c2901a940d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "train.describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.905400e+05</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>5.905400e+05</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>581607.000000</td>\n",
              "      <td>588975.000000</td>\n",
              "      <td>588963</td>\n",
              "      <td>586281.000000</td>\n",
              "      <td>588969</td>\n",
              "      <td>524834.000000</td>\n",
              "      <td>524834.000000</td>\n",
              "      <td>238269.000000</td>\n",
              "      <td>37627.000000</td>\n",
              "      <td>496084</td>\n",
              "      <td>137291</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>309743.000000</td>\n",
              "      <td>327662.000000</td>\n",
              "      <td>421618.000000</td>\n",
              "      <td>280699.000000</td>\n",
              "      <td>73187.000000</td>\n",
              "      <td>38917.000000</td>\n",
              "      <td>74926.000000</td>\n",
              "      <td>74926.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>144233.000000</td>\n",
              "      <td>140872.000000</td>\n",
              "      <td>66324.000000</td>\n",
              "      <td>66324.000000</td>\n",
              "      <td>136865.000000</td>\n",
              "      <td>136865.000000</td>\n",
              "      <td>5155.000000</td>\n",
              "      <td>5155.000000</td>\n",
              "      <td>74926.000000</td>\n",
              "      <td>74926.000000</td>\n",
              "      <td>140978.000000</td>\n",
              "      <td>144233</td>\n",
              "      <td>127320.000000</td>\n",
              "      <td>80044.000000</td>\n",
              "      <td>140985</td>\n",
              "      <td>129340</td>\n",
              "      <td>139369.000000</td>\n",
              "      <td>45113.000000</td>\n",
              "      <td>139318.000000</td>\n",
              "      <td>139261.000000</td>\n",
              "      <td>5159.000000</td>\n",
              "      <td>5169.000000</td>\n",
              "      <td>5169</td>\n",
              "      <td>4747.000000</td>\n",
              "      <td>5132.000000</td>\n",
              "      <td>5163.000000</td>\n",
              "      <td>5169</td>\n",
              "      <td>140978</td>\n",
              "      <td>140978</td>\n",
              "      <td>77565</td>\n",
              "      <td>140282</td>\n",
              "      <td>77586.000000</td>\n",
              "      <td>73289</td>\n",
              "      <td>77805</td>\n",
              "      <td>140985</td>\n",
              "      <td>140985</td>\n",
              "      <td>140985</td>\n",
              "      <td>140985</td>\n",
              "      <td>140810</td>\n",
              "      <td>118666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>75</td>\n",
              "      <td>130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>260</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>visa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debit</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IP_PROXY:TRANSPARENT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>chrome 63.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Windows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>439670</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>384767</td>\n",
              "      <td>NaN</td>\n",
              "      <td>439938</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>228355</td>\n",
              "      <td>57147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>123025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>67728</td>\n",
              "      <td>66324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3489</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5155</td>\n",
              "      <td>76232</td>\n",
              "      <td>74926</td>\n",
              "      <td>21155</td>\n",
              "      <td>22000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16874</td>\n",
              "      <td>60011</td>\n",
              "      <td>77814</td>\n",
              "      <td>134066</td>\n",
              "      <td>110452</td>\n",
              "      <td>73922</td>\n",
              "      <td>85165</td>\n",
              "      <td>47722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.282270e+06</td>\n",
              "      <td>0.034990</td>\n",
              "      <td>7.372311e+06</td>\n",
              "      <td>135.027176</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9898.734658</td>\n",
              "      <td>362.555488</td>\n",
              "      <td>153.194925</td>\n",
              "      <td>NaN</td>\n",
              "      <td>199.278897</td>\n",
              "      <td>NaN</td>\n",
              "      <td>290.733794</td>\n",
              "      <td>86.800630</td>\n",
              "      <td>118.502180</td>\n",
              "      <td>231.855423</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.092458</td>\n",
              "      <td>15.269734</td>\n",
              "      <td>0.005644</td>\n",
              "      <td>4.092185</td>\n",
              "      <td>5.571526</td>\n",
              "      <td>9.071082</td>\n",
              "      <td>2.848478</td>\n",
              "      <td>5.144574</td>\n",
              "      <td>4.480240</td>\n",
              "      <td>5.240343</td>\n",
              "      <td>10.241521</td>\n",
              "      <td>4.076227</td>\n",
              "      <td>32.539918</td>\n",
              "      <td>8.295215</td>\n",
              "      <td>94.347568</td>\n",
              "      <td>169.563231</td>\n",
              "      <td>28.343348</td>\n",
              "      <td>140.002441</td>\n",
              "      <td>42.335965</td>\n",
              "      <td>69.805717</td>\n",
              "      <td>41.638950</td>\n",
              "      <td>146.058108</td>\n",
              "      <td>0.561057</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.170502</td>\n",
              "      <td>174716.584708</td>\n",
              "      <td>0.060189</td>\n",
              "      <td>-0.058938</td>\n",
              "      <td>1.615585</td>\n",
              "      <td>-6.698710</td>\n",
              "      <td>13.285354</td>\n",
              "      <td>-38.600388</td>\n",
              "      <td>0.091023</td>\n",
              "      <td>-0.301124</td>\n",
              "      <td>99.745325</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48.053071</td>\n",
              "      <td>-344.507146</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>189.451377</td>\n",
              "      <td>14.237337</td>\n",
              "      <td>353.128174</td>\n",
              "      <td>403.882666</td>\n",
              "      <td>368.269820</td>\n",
              "      <td>16.002708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.800927</td>\n",
              "      <td>329.608924</td>\n",
              "      <td>149.070308</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.508597</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.704744e+05</td>\n",
              "      <td>0.183755</td>\n",
              "      <td>4.617224e+06</td>\n",
              "      <td>239.162522</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4901.170153</td>\n",
              "      <td>157.793246</td>\n",
              "      <td>11.336444</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.244453</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101.741072</td>\n",
              "      <td>2.690623</td>\n",
              "      <td>371.872026</td>\n",
              "      <td>529.053494</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>133.569018</td>\n",
              "      <td>154.668899</td>\n",
              "      <td>0.150536</td>\n",
              "      <td>68.848459</td>\n",
              "      <td>25.786976</td>\n",
              "      <td>71.508467</td>\n",
              "      <td>61.727304</td>\n",
              "      <td>95.378574</td>\n",
              "      <td>16.674897</td>\n",
              "      <td>95.581443</td>\n",
              "      <td>94.336292</td>\n",
              "      <td>86.666218</td>\n",
              "      <td>129.364844</td>\n",
              "      <td>49.544262</td>\n",
              "      <td>157.660387</td>\n",
              "      <td>177.315865</td>\n",
              "      <td>62.384721</td>\n",
              "      <td>191.096774</td>\n",
              "      <td>89.000144</td>\n",
              "      <td>143.669253</td>\n",
              "      <td>99.743264</td>\n",
              "      <td>231.663840</td>\n",
              "      <td>0.316880</td>\n",
              "      <td>...</td>\n",
              "      <td>14.347949</td>\n",
              "      <td>159651.816856</td>\n",
              "      <td>0.598231</td>\n",
              "      <td>0.701015</td>\n",
              "      <td>5.249856</td>\n",
              "      <td>16.491104</td>\n",
              "      <td>11.384207</td>\n",
              "      <td>26.084899</td>\n",
              "      <td>0.983842</td>\n",
              "      <td>2.789446</td>\n",
              "      <td>1.127602</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.774858</td>\n",
              "      <td>93.695502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.375360</td>\n",
              "      <td>1.561302</td>\n",
              "      <td>141.095343</td>\n",
              "      <td>152.160327</td>\n",
              "      <td>198.847038</td>\n",
              "      <td>6.897665</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.372447</td>\n",
              "      <td>97.461089</td>\n",
              "      <td>32.101995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.737502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.987000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.640000e+04</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-13.000000</td>\n",
              "      <td>-28.000000</td>\n",
              "      <td>-72.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-46.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-36.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-660.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.134635e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.027058e+06</td>\n",
              "      <td>43.321000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6019.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>67992.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>-360.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.282270e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.306528e+06</td>\n",
              "      <td>68.769000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9678.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.875000</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>125800.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>-34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>472.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.429904e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.124662e+07</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14184.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>276.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>187.958328</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>228749.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>-23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>427.000000</td>\n",
              "      <td>533.000000</td>\n",
              "      <td>486.500000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>371.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.577539e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.581113e+07</td>\n",
              "      <td>31937.391000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18396.000000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>540.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>10286.000000</td>\n",
              "      <td>11623.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4685.000000</td>\n",
              "      <td>5691.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>349.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>2255.000000</td>\n",
              "      <td>3331.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>3257.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>1429.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>869.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>873.000000</td>\n",
              "      <td>843.000000</td>\n",
              "      <td>1707.791626</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>999595.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>229.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>671.000000</td>\n",
              "      <td>661.000000</td>\n",
              "      <td>854.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>548.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 434 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        TransactionID        isFraud  ...  DeviceType  DeviceInfo\n",
              "count    5.905400e+05  590540.000000  ...      140810      118666\n",
              "unique            NaN            NaN  ...           2        1786\n",
              "top               NaN            NaN  ...     desktop     Windows\n",
              "freq              NaN            NaN  ...       85165       47722\n",
              "mean     3.282270e+06       0.034990  ...         NaN         NaN\n",
              "std      1.704744e+05       0.183755  ...         NaN         NaN\n",
              "min      2.987000e+06       0.000000  ...         NaN         NaN\n",
              "25%      3.134635e+06       0.000000  ...         NaN         NaN\n",
              "50%      3.282270e+06       0.000000  ...         NaN         NaN\n",
              "75%      3.429904e+06       0.000000  ...         NaN         NaN\n",
              "max      3.577539e+06       1.000000  ...         NaN         NaN\n",
              "\n",
              "[11 rows x 434 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx7rWjsS1UTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcYhKuNqqGmT",
        "colab_type": "code",
        "outputId": "57534271-12c1-4771-8a7f-d13cf424736d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(590540, 434)\n",
            "(506691, 433)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1srT7lCHKS1",
        "colab_type": "code",
        "outputId": "fae711bb-6404-493c-de16-822333b1829f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "data_total=pd.concat([train,test],ignore_index=True)\n",
        "del data_total['isFraud']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8P494z_y9bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_transact,train_id,test_transact,test_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9OsdqnrzeWE",
        "colab_type": "code",
        "outputId": "8dbf6785-5a1b-4241-9b70-23885d93ebcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('There are {} columns in train dataset with missing values'.format(train.isnull().any().sum()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 414 columns in train dataset with missing values\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh-ox2qmzeK4",
        "colab_type": "code",
        "outputId": "a72fb5fa-bd7e-4a18-860a-f8a0712b3724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# .nunique returns no. of unique values\n",
        "\n",
        "train_unique_value_column=[col for col in train.columns if train[col].nunique()<=1]\n",
        "test_unique_value_column=[col for col in test.columns if test[col].nunique()<=1]\n",
        "len(train_unique_value_column)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyOwb2Lj3N9B",
        "colab_type": "text"
      },
      "source": [
        "unique value column in the training set is 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzgMVuDLJhl",
        "colab_type": "code",
        "outputId": "0e7223d9-35c0-4fda-bed6-f5e4c214790a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "data_total['id_01'].value_counts(dropna=False,normalize=True).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " NaN     0.739216\n",
              "-5.0     0.150150\n",
              " 0.0     0.028759\n",
              "-10.0    0.021007\n",
              "-20.0    0.020361\n",
              "Name: id_01, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4-AG8xDTfgs",
        "colab_type": "text"
      },
      "source": [
        "##Data preparation\n",
        "removal of column with excess of null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JegHvDeSYX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "null_cols_train=[col for col in train.columns if train[col].isnull().sum()/train.shape[0]>0.9]\n",
        "null_cols_test=[col for col in test.columns if test[col].isnull().sum()/test.shape[0]>0.9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZWPi_aNSXza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
        "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC3-3aWMX6p_",
        "colab_type": "code",
        "outputId": "567ddee7-a072-481e-840d-79a22f985e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols_to_drop=list(set(null_cols_train+null_cols_test+big_top_value_cols+big_top_value_cols_test+train_unique_value_column+test_unique_value_column))\n",
        "cols_to_drop.remove('isFraud')\n",
        "len(cols_to_drop)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOBlJj-tX6dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=train.drop(cols_to_drop,axis=1)\n",
        "test=test.drop(cols_to_drop,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Teb4aSbGzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n",
        "            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n",
        "            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
        "            'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']\n",
        "for col in cat_cols:\n",
        "    if col in train.columns:\n",
        "        le = LabelEncoder()\n",
        "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
        "        train[col] = le.transform(list(train[col].astype(str).values))\n",
        "        test[col] = le.transform(list(test[col].astype(str).values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzw02R0kdGOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
        "y = train.sort_values('TransactionDT')['isFraud']\n",
        "#X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\n",
        "X_test = test.drop(['TransactionDT', 'TransactionID'], axis=1)\n",
        "del train\n",
        "test = test[[\"TransactionDT\", 'TransactionID']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjQytzudXzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# by https://www.kaggle.com/dimartinot\n",
        "def clean_inf_nan(df):\n",
        "    return df.replace([np.inf, -np.inf], np.nan)   \n",
        "\n",
        "# Cleaning infinite values to NaN\n",
        "X = clean_inf_nan(X)\n",
        "X_test = clean_inf_nan(X_test )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c_Rj0bEwwXX",
        "colab_type": "text"
      },
      "source": [
        "##Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJgzbc-X_NZT",
        "colab_type": "text"
      },
      "source": [
        "From id information ,\n",
        "\n",
        "1.Categorical variables are:\n",
        "\n",
        "  * id_12 to id_38\n",
        "\n",
        "  * DeviceInfo\n",
        "\n",
        "  * DeviceType\n",
        "\n",
        "2.Continuous variables are:\n",
        "\n",
        "  * id_01 to id_11\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gBqBCGIAa-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # For visualisation purpose\n",
        "\n",
        "# def feature_plot(X,Y,continuous):\n",
        "  \n",
        "#   Data=data_total[:8523]\n",
        "    \n",
        "#   x = Data[X]\n",
        "#   y = Data[Y]\n",
        "  \n",
        "  \n",
        "#   if continuous:    # if the data in the given feature is continuous\n",
        "    \n",
        "#     fig = plt.figure(constrained_layout=True,figsize=(17,6))\n",
        "\n",
        "#     # ----- assigning grid to for plotting \n",
        "    \n",
        "#     gs = gridspec.GridSpec(8, 8, figure=fig)\n",
        "#     ax1 = fig.add_subplot(gs[0:2, 5:7])\n",
        "#     ax2 = fig.add_subplot(gs[0:, 0:3])\n",
        "#     ax4 = fig.add_subplot(gs[2:,5:7])\n",
        "#     ax3 = fig.add_subplot(gs[2:,7:8])\n",
        "    \n",
        "#   # # #------plot-----\n",
        "    \n",
        "#      #-----PLOT WITHOUT \"Item_Outlet_Sales\"-----\n",
        "    \n",
        "#     sns.distplot(x, kde=False, ax=ax2)\n",
        "    \n",
        "#      #  -----PLOT WITH \"Item_Outlet_Sales\"------\n",
        "    \n",
        "#     ax4.scatter(x,y)\n",
        "#     ax1.hist(x,bins=70)\n",
        "#     ax3.hist(y,bins=70,orientation=\"horizontal\")\n",
        "    \n",
        "#     #   fig.suptitle(\"GridSpec\")\n",
        "\n",
        "# # Turn off tick labels on marginals\n",
        "#     plt.setp(ax1.get_xticklabels(), visible=False)\n",
        "#     plt.setp(ax3.get_yticklabels(), visible=False)\n",
        "\n",
        "# # Set labels on joint\n",
        "#     ax4.set_xlabel(X)\n",
        "#     ax4.set_ylabel(Y)\n",
        "\n",
        "# # Set labels on marginals\n",
        "#     ax3.set_xlabel(Y+' count')\n",
        "#     ax1.set_ylabel(X+' count')\n",
        "    \n",
        "#   else:     # if the data in the given feature is not continuous .\n",
        "    \n",
        "#     fig,(ax5,ax6)=plt.subplots(nrows=1,ncols=2, figsize=(16,5),dpi=90)\n",
        "    \n",
        "#     #-----PLOT WITHOUT \"Item_Outlet_Sales\"-----\n",
        "    \n",
        "#     #Show the counts of observations in each categorical bin using bars.\n",
        "#     count=sns.countplot(x, order=sorted(x.unique()), color='#597500', saturation=1, ax=ax5)                                                                                                 \n",
        "#     count.set_xticklabels(count.get_xticklabels(), rotation=80)\n",
        "#     ax5.set_title(X+' count')\n",
        "                                                                                                       \n",
        "    \n",
        "#     #  -----PLOT WITH \"Item_Outlet_Sales\"------\n",
        "    \n",
        "#     sns.boxplot(x=x, y=y, data=Data)\n",
        "# #                                                         cat_df_flights = df_flights.select_dtypes(include=['object']).copy()              #sns.catplot(x=\"Outlet_Type\", y=\"Item_Outlet_Sales\", kind=\"boxen\",data=Data);\n",
        "#     ax6.set_ylabel('Item_Outlet_Sales')\n",
        "#     ax6.set_title('Item_Outlet_Sales by '+X)\n",
        "#     plt.xticks(rotation = 80)\n",
        "#   plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9VFE9qNAazR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arxb017wLEpU",
        "colab_type": "code",
        "outputId": "7fed6741-49d9-42e0-95b4-d405353c22dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "# TransactionDt analysis\n",
        "train_transact['TransactionDT'].plot(kind='hist',\n",
        "                                        figsize=(15, 5),\n",
        "                                        label='train',\n",
        "                                        bins=50,\n",
        "                                        title='Train vs Test TransactionDT distribution')\n",
        "test_transact['TransactionDT'].plot(kind='hist',\n",
        "                                       label='test',\n",
        "                                       bins=50)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAFMCAYAAABiYSlGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRG5jrHcrEzL",
        "colab_type": "code",
        "outputId": "0a011ecb-887b-4004-92c5-6c814143c595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print('% of fraud data in train set : {}'.format(sum(list(train_transact['isFraud']==1))*100/train_transact.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of fraud data in train set : 3.499000914417313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCIvkaXqe4bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (data_total.isnull().sum() * 100 / data_total.shape[0]) < 33\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqXKvJ_q3vbx",
        "colab_type": "code",
        "outputId": "f440b2bc-3fc3-4a6b-9f4b-66da45632c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# valid_cols = (data_total.columns[(data_total.isnull().sum() * 100 / data_total.shape[0]) < 33])\n",
        "# len(valid_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2qno1Xfay2R",
        "colab_type": "code",
        "outputId": "c6aab9ad-a8a5-446a-b6fa-3e0d380d84cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# data_total1= data_total.copy().loc[:,valid_cols]\n",
        "# # data_total1.isnull().sum()  * 100 / data_total1.shape[0]\n",
        "# train_transact=train_transact.loc[:,valid_cols]\n",
        "# train_transact.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_bLzfv8g49b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list(data_total1.isnull().sum() * 100 / data_total1.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQD11E0-cGeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_corr=data_total1.dropna(axis=0,how='any')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev6S6wGWcRf-",
        "colab_type": "code",
        "outputId": "71c44e78-185b-4f8e-f023-166efa67f503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# data_corr.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(611554, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4zIGdAFcXZH",
        "colab_type": "code",
        "outputId": "ffb10f19-2714-4b60-f54b-deb49af85d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# data_total1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097231, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5rpcJUsPS6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_total1.corr(method='pearson', min_periods=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7CAjpQ3boDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_total2=data_total1.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdIeXSwawpWQ",
        "colab_type": "code",
        "outputId": "17af36fd-e3f8-45b0-9a2c-17c81d35a9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# data_total2.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1097231 entries, 0 to 1097230\n",
            "Columns: 201 entries, C1 to card6\n",
            "dtypes: float64(193), int64(3), object(5)\n",
            "memory usage: 1.6+ GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-LSEQoDwI84",
        "colab_type": "code",
        "outputId": "414c1481-db2f-4856-e15c-7073f95fee11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# cat_columns = data_total2.select_dtypes(['object']).columns\n",
        "# cat_columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['M6', 'P_emaildomain', 'ProductCD', 'card4', 'card6'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxRJpv9VUfow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_total2['card4']=data_total2['card4'].astype('category').values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUhrx2lTxq-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_total2[cat_columns]=(data_total2[cat_columns].astype('category')).apply(lambda x:x.cat.codes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QruO-ZEhUHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainf=data_total2[:590540]\n",
        "# testf=data_total2[590540:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mYl5KvNlL0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT6w5EUdJyML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwB007M7JyJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2vgU5LQJyGX",
        "colab_type": "code",
        "outputId": "c89a7a28-cbbd-4182-dce8-2647317e5d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# cat_columns = data_total.select_dtypes(['object']).columns\n",
        "# cat_columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DeviceInfo', 'DeviceType', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7',\n",
              "       'M8', 'M9', 'P_emaildomain', 'ProductCD', 'R_emaildomain', 'card4',\n",
              "       'card6', 'id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29',\n",
              "       'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSH0GhNESCpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_total[cat_columns]=(data_total[cat_columns].astype('category')).apply(lambda x:x.cat.codes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_jdQqntToNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_total=data_total.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLwHYe1FHx01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainf=data_total[:590540]\n",
        "# testf=data_total[590540:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVCC-Io3T2wP",
        "colab_type": "code",
        "outputId": "e37e65bc-0288-4cb8-bed5-cafc5cc20365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "# data_total.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C1</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>D1</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>DeviceInfo</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>M1</th>\n",
              "      <th>M2</th>\n",
              "      <th>M3</th>\n",
              "      <th>M4</th>\n",
              "      <th>M5</th>\n",
              "      <th>M6</th>\n",
              "      <th>M7</th>\n",
              "      <th>M8</th>\n",
              "      <th>M9</th>\n",
              "      <th>...</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>287.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1566</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70787.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-480.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>166.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>162</td>\n",
              "      <td>32.0</td>\n",
              "      <td>269</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 433 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    C1  C10  C11  C12   C13  C14  ...  id_33  id_34  id_35  id_36  id_37  id_38\n",
              "0  1.0  0.0  2.0  0.0   1.0  1.0  ...      0      0      0      0      0      0\n",
              "1  1.0  0.0  1.0  0.0   1.0  1.0  ...      0      0      0      0      0      0\n",
              "2  1.0  0.0  1.0  0.0   1.0  1.0  ...      0      0      0      0      0      0\n",
              "3  2.0  0.0  1.0  0.0  25.0  1.0  ...      0      0      0      0      0      0\n",
              "4  1.0  1.0  1.0  0.0   1.0  1.0  ...    269      4      2      1      2      2\n",
              "\n",
              "[5 rows x 433 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjXbIsMFJwHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(trainf, train_label, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrjmr94PH0nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def evaluate_model(ytest, ypred):\n",
        "    \n",
        "#     print('Accuracy of the model: {}\\n'.format(accuracy_score(ytest, ypred)))\n",
        "#     print('Classification report: \\n{}\\n'.format(classification_report(ytest, ypred)))\n",
        "#     print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(ytest, ypred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpApNu-YiExd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# clf = RandomForestClassifier(n_estimators=120, max_depth=4, random_state=0)\n",
        "# clf.fit(X_train,y_train)\n",
        "# ypred=clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SqFrQJnUCP4",
        "colab_type": "code",
        "outputId": "78a9bc66-ec87-49b0-9169-693bcd4848cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# evaluate_model(ypred,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model: 0.9692146171300843\n",
            "\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98    117374\n",
            "           1       0.16      0.90      0.27       734\n",
            "\n",
            "    accuracy                           0.97    118108\n",
            "   macro avg       0.58      0.94      0.63    118108\n",
            "weighted avg       0.99      0.97      0.98    118108\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            "[[113811   3563]\n",
            " [    73    661]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCO6Tv7zUNJ8",
        "colab_type": "code",
        "outputId": "3614cd02-1df7-4e63-9e8c-27be434f0dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# sum((ypred-y_test)**2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ro5ToHSUM_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMfKiqmeH0c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.ensemble import GradientBoostingClassifier\n",
        "# clf1=GradientBoostingClassifier( learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False,  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n",
        "# clf1.fit(trainf,train_label)\n",
        "# ypred1=clf1.predict(testf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qpWEXwaH0Zb",
        "colab_type": "code",
        "outputId": "af140b26-6f62-48a6-bac5-6d97ae126f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# evaluate_model(ypred1,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model: 0.9723896772445558\n",
            "\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99    116793\n",
            "           1       0.27      0.87      0.41      1315\n",
            "\n",
            "    accuracy                           0.97    118108\n",
            "   macro avg       0.63      0.92      0.70    118108\n",
            "weighted avg       0.99      0.97      0.98    118108\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            "[[113708   3085]\n",
            " [   176   1139]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_46QMnqCdf9h",
        "colab_type": "text"
      },
      "source": [
        "##LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2t-q3QVH0Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold = 5\n",
        "folds = TimeSeriesSplit(n_splits=n_fold)\n",
        "folds = KFold(n_splits=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmLekdDMfaJQ",
        "colab_type": "code",
        "outputId": "681984e4-3424-4059-9597-2010745eefb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "params = {'num_leaves': 256,\n",
        "          'min_child_samples': 79,\n",
        "          'objective': 'binary',\n",
        "          'max_depth': 13,\n",
        "          'learning_rate': 0.03,\n",
        "          \"boosting_type\": \"gbdt\",\n",
        "          \"subsample_freq\": 3,\n",
        "          \"subsample\": 0.9,\n",
        "          \"bagging_seed\": 11,\n",
        "          \"metric\": 'auc',\n",
        "          \"verbosity\": -1,\n",
        "          'reg_alpha': 0.3,\n",
        "          'reg_lambda': 0.3,\n",
        "          'colsample_bytree': 0.9,\n",
        "          #'categorical_feature': cat_cols\n",
        "         }\n",
        "result_dict_lgb = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='auc', plot_feature_importance=True,\n",
        "                                                      verbose=500, early_stopping_rounds=200, n_estimators=5000, averaging='usual', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1 started at Tue Sep  3 07:27:43 2019\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[500]\ttraining's auc: 0.992548\ttraining's auc: 0.992548\tvalid_1's auc: 0.916554\tvalid_1's auc: 0.916554\n",
            "Early stopping, best iteration is:\n",
            "[479]\ttraining's auc: 0.991868\ttraining's auc: 0.991868\tvalid_1's auc: 0.916711\tvalid_1's auc: 0.916711\n",
            "Fold 2 started at Tue Sep  3 07:36:57 2019\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[500]\ttraining's auc: 0.993349\ttraining's auc: 0.993349\tvalid_1's auc: 0.932098\tvalid_1's auc: 0.932098\n",
            "Early stopping, best iteration is:\n",
            "[626]\ttraining's auc: 0.995649\ttraining's auc: 0.995649\tvalid_1's auc: 0.932798\tvalid_1's auc: 0.932798\n",
            "Fold 3 started at Tue Sep  3 07:47:50 2019\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[500]\ttraining's auc: 0.993672\ttraining's auc: 0.993672\tvalid_1's auc: 0.927699\tvalid_1's auc: 0.927699\n",
            "Early stopping, best iteration is:\n",
            "[333]\ttraining's auc: 0.987981\ttraining's auc: 0.987981\tvalid_1's auc: 0.928203\tvalid_1's auc: 0.928203\n",
            "Fold 4 started at Tue Sep  3 07:55:09 2019\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[500]\ttraining's auc: 0.993241\ttraining's auc: 0.993241\tvalid_1's auc: 0.947825\tvalid_1's auc: 0.947825\n",
            "Early stopping, best iteration is:\n",
            "[492]\ttraining's auc: 0.993007\ttraining's auc: 0.993007\tvalid_1's auc: 0.94785\tvalid_1's auc: 0.94785\n",
            "Fold 5 started at Tue Sep  3 08:04:27 2019\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[500]\ttraining's auc: 0.993943\ttraining's auc: 0.993943\tvalid_1's auc: 0.923622\tvalid_1's auc: 0.923622\n",
            "Early stopping, best iteration is:\n",
            "[439]\ttraining's auc: 0.992424\ttraining's auc: 0.992424\tvalid_1's auc: 0.924078\tvalid_1's auc: 0.924078\n",
            "CV mean score: 0.9299, std: 0.0104.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAALJCAYAAAAXqBjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyY_9UhCYV_S",
        "colab_type": "code",
        "outputId": "1c4178ae-ee35-43af-fa5d-e818873d162c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# sample_submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663549</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663550</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663551</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663552</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663553</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud\n",
              "0        3663549      0.5\n",
              "1        3663550      0.5\n",
              "2        3663551      0.5\n",
              "3        3663552      0.5\n",
              "4        3663553      0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y3sewqMT7TV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission['isFraud'] = result_dict_lgb['prediction']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij3MqDQY2f1r",
        "colab_type": "text"
      },
      "source": [
        "##xgb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmbAA5tn2eHj",
        "colab_type": "code",
        "outputId": "31e5738d-59a5-4dea-f4c0-0fc66f38e46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xgb_params = {'eta': 0.04,\n",
        "              'max_depth': 5,\n",
        "              'subsample': 0.85,\n",
        "              'objective': 'binary:logistic',\n",
        "              'eval_metric': 'auc',\n",
        "              'silent': True,\n",
        "              'nthread': -1,\n",
        "              'tree_method': 'gpu_hist'}\n",
        "result_dict_xgb = train_model_classification(X=X, X_test=X_test, y=y, params=xgb_params, folds=folds, model_type='xgb', eval_metric='auc', plot_feature_importance=False,\n",
        "                                                      verbose=500, early_stopping_rounds=200, n_estimators=5000, averaging='rank')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1 started at Tue Sep  3 11:20:19 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-auc:0.765415\tvalid_data-auc:0.772437\n",
            "Multiple eval metrics have been passed: 'valid_data-auc' will be used for early stopping.\n",
            "\n",
            "Will train until valid_data-auc hasn't improved in 200 rounds.\n",
            "[500]\ttrain-auc:0.93749\tvalid_data-auc:0.893397\n",
            "[1000]\ttrain-auc:0.957447\tvalid_data-auc:0.904928\n",
            "[1500]\ttrain-auc:0.969254\tvalid_data-auc:0.909481\n",
            "[2000]\ttrain-auc:0.976502\tvalid_data-auc:0.911504\n",
            "[2500]\ttrain-auc:0.98181\tvalid_data-auc:0.911689\n",
            "Stopping. Best iteration:\n",
            "[2333]\ttrain-auc:0.980188\tvalid_data-auc:0.911799\n",
            "\n",
            "Fold 2 started at Tue Sep  3 12:00:08 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-auc:0.768715\tvalid_data-auc:0.780718\n",
            "Multiple eval metrics have been passed: 'valid_data-auc' will be used for early stopping.\n",
            "\n",
            "Will train until valid_data-auc hasn't improved in 200 rounds.\n",
            "[500]\ttrain-auc:0.938423\tvalid_data-auc:0.909229\n",
            "[1000]\ttrain-auc:0.956768\tvalid_data-auc:0.916765\n",
            "[1500]\ttrain-auc:0.968469\tvalid_data-auc:0.920332\n",
            "[2000]\ttrain-auc:0.976507\tvalid_data-auc:0.922362\n",
            "[2500]\ttrain-auc:0.981729\tvalid_data-auc:0.923379\n",
            "Stopping. Best iteration:\n",
            "[2762]\ttrain-auc:0.984108\tvalid_data-auc:0.923638\n",
            "\n",
            "Fold 3 started at Tue Sep  3 12:45:38 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-auc:0.770117\tvalid_data-auc:0.753946\n",
            "Multiple eval metrics have been passed: 'valid_data-auc' will be used for early stopping.\n",
            "\n",
            "Will train until valid_data-auc hasn't improved in 200 rounds.\n",
            "[500]\ttrain-auc:0.938546\tvalid_data-auc:0.904677\n",
            "[1000]\ttrain-auc:0.9583\tvalid_data-auc:0.91422\n",
            "[1500]\ttrain-auc:0.969849\tvalid_data-auc:0.917848\n",
            "[2000]\ttrain-auc:0.977398\tvalid_data-auc:0.919444\n",
            "Stopping. Best iteration:\n",
            "[1943]\ttrain-auc:0.976658\tvalid_data-auc:0.919615\n",
            "\n",
            "Fold 4 started at Tue Sep  3 13:18:30 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-auc:0.773239\tvalid_data-auc:0.780176\n",
            "Multiple eval metrics have been passed: 'valid_data-auc' will be used for early stopping.\n",
            "\n",
            "Will train until valid_data-auc hasn't improved in 200 rounds.\n",
            "[500]\ttrain-auc:0.93397\tvalid_data-auc:0.925024\n",
            "[1000]\ttrain-auc:0.95474\tvalid_data-auc:0.934199\n",
            "[1500]\ttrain-auc:0.967533\tvalid_data-auc:0.938737\n",
            "[2000]\ttrain-auc:0.975504\tvalid_data-auc:0.940629\n",
            "[2500]\ttrain-auc:0.981109\tvalid_data-auc:0.941254\n",
            "Stopping. Best iteration:\n",
            "[2504]\ttrain-auc:0.981146\tvalid_data-auc:0.941289\n",
            "\n",
            "Fold 5 started at Tue Sep  3 14:00:01 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-auc:0.74453\tvalid_data-auc:0.731931\n",
            "Multiple eval metrics have been passed: 'valid_data-auc' will be used for early stopping.\n",
            "\n",
            "Will train until valid_data-auc hasn't improved in 200 rounds.\n",
            "[500]\ttrain-auc:0.938353\tvalid_data-auc:0.904606\n",
            "[1000]\ttrain-auc:0.958153\tvalid_data-auc:0.912638\n",
            "[1500]\ttrain-auc:0.969304\tvalid_data-auc:0.914633\n",
            "[2000]\ttrain-auc:0.976799\tvalid_data-auc:0.915275\n",
            "Stopping. Best iteration:\n",
            "[1896]\ttrain-auc:0.975439\tvalid_data-auc:0.915788\n",
            "\n",
            "CV mean score: 0.9224, std: 0.0102.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-V6cYuipHJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission_xgb=sample_submission.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObrbNaLlkW0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.sort_values('TransactionDT')\n",
        "test['prediction'] = result_dict_xgb['prediction']\n",
        "sample_submission_xgb['isFraud'] = pd.merge(sample_submission_xgb, test, on='TransactionID')['prediction']\n",
        "sample_submission_xgb.to_csv('submission_xgb.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89RBfGlaov5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.sort_values('TransactionDT')\n",
        "test['prediction'] = result_dict_lgb['prediction'] + result_dict_xgb['prediction']\n",
        "sample_submission_xgb['isFraud'] = pd.merge(sample_submission_xgb, test, on='TransactionID')['prediction']\n",
        "sample_submission_xgb.to_csv('blend.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmOZIvfDaSGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample_submission['isFraud']=ypred1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiKmD-MJ-cOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample_submission_xgb['isFraud']=result_dict_xgb['prediction']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF05WA_VEdi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CyXeMYqEdRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqiHpPFacWZ0",
        "colab_type": "code",
        "outputId": "a6509285-1751-4258-cbbc-805155a25926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "sample_submission_xgb.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663549</td>\n",
              "      <td>147522.801844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663550</td>\n",
              "      <td>126158.201157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663551</td>\n",
              "      <td>147451.202255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663552</td>\n",
              "      <td>81153.002143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663553</td>\n",
              "      <td>174279.501846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID        isFraud\n",
              "0        3663549  147522.801844\n",
              "1        3663550  126158.201157\n",
              "2        3663551  147451.202255\n",
              "3        3663552   81153.002143\n",
              "4        3663553  174279.501846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMLquPQPcS9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission.to_csv('final_sub.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}